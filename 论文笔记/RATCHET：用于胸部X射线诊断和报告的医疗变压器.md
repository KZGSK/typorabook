# RATCHET：用于胸部X射线诊断和报告的医疗变压器

RATCHET: Medical Transformer for Chest X-ray Diagnosis and Reporting

论文：MICCAI-2021   笔记：2022.7.5

## 问题

就是想提高报告书写效率，减少工作人员工作量

## 提出方法

开发了一种基于转换器的CNN编码器到RNN解码器架构，用于生成胸片报告。我们使用注意力来定位图像中的感兴趣区域，并显示相应生成文本的网络关注点。

## 模型结构

<img src="../image/image-20220705174806060.png" alt="image-20220705174806060" style="zoom: 80%;" />

训练报告生成模型有三个关键方面：（i）文本预处理（ii）标记化（tokenization） （iii）语言模型制定/训练。

### 语言预处理和标记化

医学领域存在很多专业词汇，影响tokenization 过程。因为医学词源涉及复合多个拉丁词缀，从而产生许多独特的单词以及测量值。太多的不频繁标记会阻碍模型的学习能力，而使用词汇表外（OOV）标记修剪太多的不频繁标记会导致词汇发育不良。或者可以使用更复杂的标记器，例如BPE，其中单词被分解为一个或多个子单词。这消除了对未登陆词标记的依赖，还可以将标点符号合并到词汇语料库中。这里用Huggingface库，频繁的单词应该被赋予唯一的ID，而频率较低的单词应该分解成最能保留其含义的子单词。

## Transformer结构

这里编码器使用的是Densenet121.解码器架构是普通transformer。

## 结构

感觉就是普通Transformer，也可能是我忽视了创新点。。。不过tokenization技术以前没有特别关注