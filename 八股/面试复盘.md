# 面试复盘

## 缓存一致性问题

缓存系统的数据一致性通常包括持久化层和缓存层的一致性(MySQL与Redis)、以及多级缓存之间(本地缓存+redis)的一致性

### MySQL与Redis

#### 旁路缓存模式

在读请求中，首先请求缓存，若缓存命中，则直接返回缓存中的数据；若缓存未命中，则查询数据库并将查询结果更新至缓存，然后返回查询出的数据。在写请求中，先**更新数据库，再删除缓存**。

**为什么不直接更新缓存？**

首先是**性能**，当该缓存对应的结果需要消耗大量的计算过程才能得到时，比如需要访问多张数据库表并联合计算，那么在写操作中更新缓存的动作将会是一笔不小的开销。同时，当写操作较多时，可能也会存在刚更新的缓存还没有被读取到，又再次被更新的情况，这样的更新是白白消耗机器性能的，会导致缓存利用率不高。而等到读请求未命中缓存时再去更新，也符合懒加载的思路，需要时再进行计算。

<img src="../image/image-20240327154819112.png" alt="image-20240327154819112" style="zoom:50%;" />

其次是**安全**，在并发场景下，在写请求中更新缓存可能会引发数据的不一致问题。两个线程先后更新数据库，有先后更新缓存。但由于网络延迟，更新缓存的顺序可能与数据库不一致。造成缓存里的是旧值。

**为什么不是先删除缓存？**

<img src="../image/image-20240327154929921.png" alt="image-20240327154929921" style="zoom:50%;" />

先删了缓存，还没等更新数据库，又来一个线程读了数据，缓存种又被存进了旧值。

但这种情况可以利用延迟双删的方案解决。开始删除缓存，过段时间再删一次。但双删的缺点就是这个延迟很难预估。

**更新数据库，再删除缓存的模式会又不一致问题吗？**

<img src="../image/image-20240327155048408.png" alt="image-20240327155048408" style="zoom:50%;" />

**情况一：**更新数据库前，缓存失效，有线程读，还没等写入缓存，就触发了删除缓存。这样旧值在删除缓存后又被添加了进去

这种场景的出现，不仅需要缓存失效且读写并发执行，而且还需要读请求查询数据库的执行早于写请求更新数据库，同时读请求的执行完成晚于写请求。足以见得，这种不一致场景产生的条件非常严格，在实际的生产中出现的可能性较小。

**情况二：**读请求在删缓存之前，更新Mysql之后。这样读的是旧值。虽然在下一次读请求中，缓存会被更新，但如果业务层面对这种情况的容忍度较低，可以采用加锁在写请求中保证“更新数据库&删除缓存”的串行执行为原子性操作。

####**补偿机制**

可能存在更新数据库成功，但删除缓存失败的场景，产生数据的不一致的问题。针对可能出现的删除失败问题，目前业界主要有以下几种补偿机制。

**删除重试机制**

我们可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

**订阅 MySQL binlog，再操作缓存**

binlog文件中记录的是对数据库的各种修改操作。引入Canal中间件，模拟主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。

####读穿 / 写穿

Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。

#### 写回

Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。

#### 缓存更新失败怎么办

Redis的事务并不支持回滚功能，Redis命令在事务处理期间发生错误，原先的操作并不会回滚。

先操作数据库再操作缓存，但是MySQL操作成功，而Redis异常，此时缓存数据不一致，如何回滚Mysql。

redis事务+数据库的事务来保证事务一致性的问题。

### 本地缓存一致性

两级缓存与数据库的数据要保持一致，一旦数据发生了修改，在修改数据库的同时，本地缓存、远程缓存应该同步更新。

分布式环境下，一级缓存之间也会存在一致性问题，当一个节点下的本地缓存修改后，需要通知其他节点也刷新本地缓存中的数据

解决方案1: Redis

利用Reids的发布订阅功能来实现分布式缓存下不用节点的缓存同步。

解决方案2: MQ

一般现在部署都是集群部署，有多个不同节点的本地缓存; 可以使用MQ的广播模式，当数据修改时向MQ发送消息，节点监听并消费消息，删除本地缓存，达到最终一致性；

解决方案3：Canal + MQ

如果你不想在你的业务代码发送MQ消息，还可以适用近几年比较流行的方法：订阅数据库变更日志，再操作缓存。Canal 订阅Mysql的 Binlog日志，当发生变化时向MQ发送消息，进而也实现数据一致性。

以L2Cache方案为例

获得数据：查L1缓存-查L2缓存-查数据库依次进行

缓存的更新策略：

缓存更新包含了对L1、L2缓存的操作，同时会通知其他缓存节点进行缓存更新。

**主动更新模式**

获得数据时，数据不存在，则重新加载内存。

- 具体来说L1不存在，从L2取，L2存在，更新L1。L2不存在，从数据库中取。

  如果L2不存在，从数据库中读取数据，通过CAS放进L2中。并在之后通过MQ/Redis发布更新缓存的消息，使用refrash方法刷新缓存更新L1。若不存在L2，直接发布消息更新L1

数据发生改变时，先写DB, 先更新L2,再更新L1。更新L1时调用MQ/Redis发布更新缓存的消息，保证一级缓存之间的一致性。

**自动更新模式**

通过定期刷新过期缓存（只对过期缓存进行重新加载），尽可能的保证分布式缓存的一致性。考虑到性能问题，不建议通过 定期刷新过期缓存 的方式来刷新缓存，因为当缓存数据量很大时，定时刷新过期缓存，会占用cpu资源。

**缓存淘汰**

获取缓存时去检查缓存是否过期，若过期则淘汰缓存。对于L2可以由自己的淘汰机制管理

#### Redis发布订阅机制

Redis目前支持普通订阅和模式订阅.

**普通订阅**

![image-20240328093004452](../image/image-20240328093004452.png)

Redis服务端使用了字典来存储订阅关系。key为频道名字，值为订阅同一频道组成的client链表。

发消息：在 pubsub_channels 字典里找到频道 channel 的订阅者列表，然后将消息发送给列表上所有客户端；

**模式订阅**

![image-20240328093133675](../image/image-20240328093133675.png)

Redis将所有模式的订阅关系都保存在服务器状态的 pubsub_patterns 链表，链表的每个节点都包含着一个 pubsub Pattern 结构，这个结构的 pattern 属性记录了被订阅的模式，而 client 属性则记录了订阅模式的客户端。

发消息：遍历 pubsub_patterns 链表，查找与channel 频道相匹配的 pattern 模式，并将消息发送给订阅了这些 pattern 模式的客户端。

在L2中，多个客户端订阅了同一个通道，当本地缓存更新时，会发送消息，每个订阅的客户端都会消费消息，对自己的L1缓存执行相应设定的操作，比如：更新缓存或删除缓存。

#### 消息队列

生产者只能把消息发送给一个exchange，exchange只做一件简单的事情：一方面它们接收从生产者发送过来的消息，另一方面，它们把接收到的消息推送给队列。一个exchage必须清楚地知道如何处理一条消息。

当多个消费者希望订阅同一个消息进行处理时，则需要将声明交换器为fanout，它使得生产者生产的消息以广播的形式加入到所有订阅的队列中去，不同的消费者获得队列中的消息进行消费。注意，消费者不能连接同一个队列，这样消息会产生竞争，只能由1个消费者获得。

#### 订阅Binlog来实现缓存同步

Binlog是MySQL中的一种二进制日志文件。它可以记录MySQL内部对数据库的所有修改，用于主从复制。存在3种模式，Statement(修改sql语句)、Row（数据变化)、Mixed(前两种模式的结合,会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式)。

**借助Canal监听日志实现同步**

Canal可以解析binlog增量日志，canal 模拟 MySQL slave 的交互协议，伪装自己为从节点，向 MySQL master获取增量日志并解析。然后利用MQ同步数据到缓存。

## 接口性能

**指标**

QPS:每秒请求数

TPS:每秒事务数，一个事务是指一个客户端向服务器发送请求然后服务器做出响应的过程。

QPS vs TPS：对于一个页面的一次访问，形成一个TPS；但一次页面请求，可能产生多次对服务器的请求，会有多个QPS

RT（Response-time）响应时间：客户端发起请求到收到服务器响应结果的时间

并发数：是指系统同时能处理的请求数量，这个也反应了系统的负载能力。

吞吐量：一次性能测试过程中网络上传输的数据量综合，吞吐量是指系统在单位时间内处理请求的数量，TPS、QPS都是吞吐量的常用量化指标。

吞吐率=吞吐量 / 传输时间

## 缓存淘汰策略

###LRU

当规定空间用尽且需要放入新数据的时候，会优先淘汰最久未被访问的数据

缺点：在存在周期性的局部热点数据场景，有大概率可能造成**缓存污染**。，影响命中率

优点：实现简单、对突发性的稀疏流量表现很好。

改进：

LRU-K：LRU-K有两个队列，新来的元素先进入到历史访问队列中，该队列用于记录元素的访问次数，采用的淘汰策略是LRU或者FIFO，当历史队列中的元素访问次数达到K的时候，才会进入缓存队列。也就是说没有到达K次访问的数据并不会被缓存。相比于LRU，缓存数据更不容易被替换，而且偶发性的数据不易被缓存。在保证了缓存数据纯净的同时还提高了热点数据命中率。

Two Queues与LRU-K相比，他也同样是两个队列，不同之处在于，他的队列一个是缓存队列，一个是FIFO队列，当新元素进来的时候，首先进入FIFO队列，当该队列中的元素被访问的时候，会进入LRU队列。

### LFU

如果一个数据在最近一段时间内**使用次数很少，使用频率最低**，那么在将来一段时间内被使用的可能性也很小。与LRU的区别在于LRU是以时间先后来衡量，LFU是以时间段内的使用次数衡量

缺点：需要额外的空间记录频率；在存在局部突发流量场景下，有大概率可能造成**缓存污染**， 算法命中率会急剧下降。

优点：实现简单、对突发性的稀疏流量表现很好。

改进：

#### TinyLFU

<img src="../image/image-20240402113013837.png" alt="image-20240402113013837" style="zoom:50%;" />

使用Count-Min Sketch算法存储访问频率，极大的节省空间；并且减少hash碰撞。可以看作是布隆过滤器的同源的算法。一个hash函数的hash值匹配到一列中，列中的数值频率+1.使用这种二维的记录形式比hashmap减小hash冲突。估算计数时，根据哈希映射到每一行的对应位置，然后读取所有行的计数，返回其中最小的一个。

Count-Min Sketch用n个hash函数会存访问次数,但没必要存太大的数字。超过15就能认为是热门了，个long有64位，可以存16个4位。

为了让缓存降低“新鲜度”，剔除掉过往频率很高，但之后不经常的缓存，Caffeine 有一个 Freshness Mechanism。就是当整体的统计计数（当前所有记录的频率统计之和，这个数值内部维护）达到某一个值时，那么所有记录的频率统计除以 2。

TinyLFU 在面对突发性的稀疏流量（sparse bursts）时表现很差，因为新的记录（new items）还没来得及建立足够的频率就被剔除出去了，这就使得命中率下降。

###W-TinyLFU

Caffeine使用W-TinyLFU作为淘汰策略。W-TinyLFU = LRU + LFU

![image-20240402114237172](../image/image-20240402114237172.png)

**窗口缓存**

LFU需要记录频率，但开始时频率很低可能会被淘汰。W-TinyLFU中使用LRU来作为一个`窗口缓存`，主要是让元素能够有机会在`窗口缓存`中去积累它的频率，避免因为频率很低而直接被淘汰。

**频率统计**

W-TinyLFU中使用BloomFilter+CountMinSketch来统计元素的访问频率，BloomFilter作为一个前置计数器，而CountMinSketch则作为主计数器。BloomFilter避免前面所提到的稀疏流量对CountMinSketch计数器的影响，也就是稀疏流量只会在BloomFilter中进行计数（可以当成是最大值为1的计数），换句话说就是如果BloomFilter中没有计数则先把这次的计数加到BloomFilter中。需要BloomFilter的主要原因是CountMinSketch也是基于概率的，在计数的正确性一定的情况下，越多的元素进入CountMinSketch计数器，那么CountMinSketch就需要越大和越多的哈希函数。而BloomFilter可以帮忙抵挡那部分计数值还不需要那么大的元素，这样我们就可以减小CountMinSketch计数器的大小。

CountMinSketch的优点是可以减小存储空间

**保鲜机制**

前面提到了LFU建立起一定频率后就难以被淘汰，们会在进行一定次数的操作之后，把前面提到的BloomFilter和CountMinSketch计数器的计数值进行衰减。对于BloomFilter会直接清空（置0），而CountMinSketch则会把每个元素的计数除以二。

**主缓存**SLRU

SLRU就是把缓存分成两段，一段是`淘汰段`，一段是`保护段`，两个段都是普通的LRU实现。第一次被访问的元素将进入淘汰段，只有处于淘汰段中的元素再次被访问才会进入保护段。保护段中的元素如果被淘汰将会再次进入淘汰段，而淘汰段的元素被淘汰则会被移出缓存。

简单来说就是每个元素至少两次被访问才会进入保护段，而保护段中的元素是受保护的，它更难被淘汰，因为就算被淘汰也只是移动到淘汰段。

添加元素的流程如下：

- 增加元素的计数
- 把元素添加到窗口缓存
- 如果窗口缓存中有元素candidate被淘汰
  - 获取主缓存中最可能被淘汰的元素`victim`
  - candidate和victim根据频率进行PK
  - 如果candidate获胜则进入主缓存
  - 失败则被淘汰

获取元素的流程如下：

- 增加元素的计数
- 尝试从窗口缓存获取
- 如果窗口缓存没有则尝试从主缓存获取
- 如果都没有则获取失败

## MySQL连接池

**为什么用连接池**

- **资源复用**。避免了频繁的创建、销毁带来的性能开销减少系统资源消耗的基础上，增加了系统运行的稳定性，主要体现在减少内存碎片和线程或进程的临时创建。

- **更快的响应速度**。由于程序启动时就准备好了若干连接备用，业务请求直接使用即可，不需要实时进行连接的创建、权限验证及销毁等操作，从而减少了系统的响应时间。

- **统一的连接管理，避免数据库连接泄漏**。可预先设定连接占用的超时时间，假如某条连接被占用超过设定值，可以强制回收该连接。

连接过程：

客户端发起连接请求，TCP三次握手

Mysql内部权限验证

SQL执行语句

Mysql关闭

断开连接，TCP四次挥手

## TheadLocal跨线程共享

**InheritableThreadLocal**：实现父子线程变量共享

原理：Thread对象，通过内部的ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;维护从父线程（创建该线程的线程）继承而来的数据

原理就是在创建线程时，如果当前线程的inheritableThreadLocals不为null，那么将会复制一份保存在自己的ThreadLocal.ThreadLocalMap inheritableThreadLocals中

缺点：线程池无法使用，因为只有在创建的时候会copy一份，但线程池中线程可能一直存活，看不到父线程的变换

 **transmittable-thread-local**：

inheritableThreadLocal在线程创建的时候才会copy，所以transmittable是对线程池提交任务时进行增强，会捕获当前线程中所有注册的TheadLocal。

具体来说，在进行ThreadLocal的set方法时会将当前的ThreadLcal保存进一个holder中，holder由final static修饰，只存在一份。使用线程池时，构造线程任务时会遍历holder，取出所有父线程set的值存进一个HashMap中作为快照存储。执行线程任务时会执行方法来获取快照作为capture。capture是捕获到的父线程里的本地变量值。但子线程本身在创建的时候会有一个原生的本地变量backup。backup可能存在一些值是capture里没有的，需要在backup删除。因为子线程的作用是进行主线程的异步，应当不适应子线程本身存在的变量。在任务执行完后在恢复原始的backup

## diamond

### 如何实现配置变更的推送

推模式指的是客户端与服务端建立好网络长连接，服务方有相关数据，直接通过长连接通道推送到客户端。其优点是及时，一旦有数据变更，客户端立马能感知到；另外对客户端来说逻辑简单，不需要关心有无数据这些逻辑处理。缺点是不知道客户端的数据消费能力，可能导致数据积压在客户端，来不及处理。

拉模式指的是客户端主动向服务端发出请求，拉取相关数据。其优点是此过程由客户端发起请求，故不存在推模式中数据积压的问题。缺点是可能不够及时，对客户端来说需要考虑数据拉取相关逻辑，何时去拉，拉的频率怎么控制等等。

diamond是基于推模型的长轮询方案，客户端使用定时任务，每隔时间发起请求，定义超时时间，在未超时是一直监听变更。服务端每隔一段时间检测是否配置变换，配置变换返回具体新配置。

diamond具有一套完备的容灾机制，容灾机制涉及到client和server两部分，主要包括以下几个方面：

server存储数据是“数据库 + 本地文件”的方式，client订阅数据时，访问的是本地文件，不查询数据库，这样即使数据库出问题了，仍然不影响client的订阅。并且server是一个集群，一个出问题可以自动切换其他服务端。

client每次从server获取到数据后，都会将数据保存在本地文件系统，diamond称之为snapshot，即数据快照。当client下次启动发现在超时时间内所有server均不可用（可能是网络故障），它会使用snapshot中的数据快照进行启动。

client每次从server获取到数据后，都会进行MD5校验（数据保存在response body，MD5保存在response header），以防止因网络故障造成的数据不完整，MD5校验不通过直接抛出异常。

## RPC

客户端在不知道调用细节的情况下，调用存在于远程计算机上的某个对象，就像调用本地应用程序中的对象一样。

获取可用的远程服务器-表示数据-传递数据-调用方法

服务端将自己服务节点注册到注册中心，客户端会订阅注册中心拿到可用的远程调用方法，当服务节点变换时会通知客户端。

调用流程：

1. 服务消费方（client）调用以本地调用方式调用服务；
2. client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；
3. client stub找到服务地址，并将消息发送到服务端；
4. server stub收到消息后进行解码；
5. server stub根据解码结果调用本地的服务；
6. 本地服务执行并将结果返回给server stub；
7. server stub将返回结果打包成消息并发送至消费方；
8. client stub接收到消息，并进行解码；
9. 服务消费方得到最终结果。

使用动态代理来实现需求。代理类的invoke方法中封装了与远端服务通信的细节。
